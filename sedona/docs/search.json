[{"path":"/articles/apache-sedona.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to Apache Sedona for R","text":"apache.sedona sparklyr-based R interface Apache Sedona. presents Apache Sedona offer idiomatic frameworks constructs R (e.g., one can build spatial Spark SQL queries using Sedona UDFs conjunction wide range dplyr expressions), hence making Apache Sedona highly friendly R users. Generally speaking, working Apache Sedona, one choose following two modes: Manipulating Sedona Spatial Resilient Distributed Datasets spatial-RDD-related routines Querying geometric columns within Spatial DataFrames Sedona spatial UDFs former option enables fine-grained control low-level implementation details (e.g., index build spatial queries, data structure use spatial partitioning, etc), latter simpler leads straightforward integration dplyr, sparklyr, sparklyr extensions (e.g., one can build ML feature extractors Sedona UDFs connect ML pipelines using ml_*() family functions sparklyr, hence creating ML workflows capable understanding spatial data). data spatial RDDs can imported Spark DataFrames geometry columns vice versa, one can switch abovementioned two modes fairly easily. moment apache.sedona consists following components: Reading/writing spatial data WKT, WKB, GeoJSON formats Shapefile reader Spatial partition, index, join, KNN query, range query operations Visualization routines See SQL APIs list available UDFs Functions importing data spatial RDDs Spark DataFrames vice versa","code":""},{"path":"/articles/apache-sedona.html","id":"connect-to-spark","dir":"Articles","previous_headings":"","what":"Connect to Spark","title":"Introduction to Apache Sedona for R","text":"ensure Sedona serialization routines, UDTs, UDFs properly registered creating Spark session, one simply needs attach apache.sedona instantiating Spark connection. apache.sedona take care rest. example, create Sedona-capable Spark connection YARN client mode, create Sedona-capable Spark connection Apache Spark instance running locally. sparklyr, one can easily inspect Spark connection object sanity-check properly initialized Sedona-related dependencies, e.g., information connecting Spark sparklyr, see https://therinspark.com/connections.html ?sparklyr::spark_connect. Also see Initiate Spark Context Initiate Spark Session minimum recommended dependencies Apache Sedona.","code":"library(sparklyr) library(apache.sedona)  spark_home <- \"/usr/lib/spark\"  # NOTE: replace this with your $SPARK_HOME directory sc <- spark_connect(master = \"yarn\", spark_home = spark_home) library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"local\") print(sc$extensions$packages) #> [1] \"org.datasyslab:geotools-wrapper:1.4.0-28.2\" #> [2] \"edu.ucar:cdm-core:5.4.2\" spark_session(sc) %>%   invoke(\"%>%\", list(\"conf\"), list(\"get\", \"spark.kryo.registrator\")) %>%   print() #> [1] \"org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator\""},{"path":"/articles/apache-sedona.html","id":"dplyr-workflows","dir":"Articles","previous_headings":"","what":"dplyr workflows","title":"Introduction to Apache Sedona for R","text":"apache.sedona extends sparklyr integrates dplyr workflows. See sparklyr cheatsheet","code":"library(dplyr)"},{"path":[]},{"path":"/articles/apache-sedona.html","id":"copying-from-r","dir":"Articles","previous_headings":"dplyr workflows > Loading data","what":"Copying from R","title":"Introduction to Apache Sedona for R","text":"Data loaded R can copied Spark using copy_to. Columns containing spatial information can converted geometry type Spark DataFrames (GeometryUDT) Spark SQL functions ST_GeomFromText ST_GeomFromText, see Vector constructors Raster input output. automatic translation sf objects provided, need converted text (binary) format copying spark.","code":"data <- readr::read_tsv(\"../../binder/data/county_small.tsv\", col_names = FALSE, show_col_types = FALSE) data %>% glimpse() #> Rows: 100 #> Columns: 18 #> $ X1  <chr> \"POLYGON ((-97.019516 42.004097,-97.019519 42.004933,-97.019527 42… #> $ X2  <chr> \"31\", \"53\", \"35\", \"31\", \"31\", \"72\", \"46\", \"48\", \"06\", \"21\", \"39\", … #> $ X3  <chr> \"039\", \"069\", \"011\", \"109\", \"129\", \"085\", \"099\", \"327\", \"091\", \"05… #> $ X4  <chr> \"00835841\", \"01513275\", \"00933054\", \"00835876\", \"00835886\", \"01804… #> $ X5  <chr> \"31039\", \"53069\", \"35011\", \"31109\", \"31129\", \"72085\", \"46099\", \"48… #> $ X6  <chr> \"Cuming\", \"Wahkiakum\", \"De Baca\", \"Lancaster\", \"Nuckolls\", \"Las Pi… #> $ X7  <chr> \"Cuming County\", \"Wahkiakum County\", \"De Baca County\", \"Lancaster … #> $ X8  <chr> \"06\", \"06\", \"06\", \"06\", \"06\", \"13\", \"06\", \"06\", \"06\", \"06\", \"06\", … #> $ X9  <chr> \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", \"H1\", … #> $ X10 <chr> \"G4020\", \"G4020\", \"G4020\", \"G4020\", \"G4020\", \"G4020\", \"G4020\", \"G4… #> $ X11 <dbl> NA, NA, NA, 339, NA, 490, NA, NA, NA, NA, 248, NA, NA, 108, 338, N… #> $ X12 <dbl> NA, NA, NA, 30700, NA, 41980, 43620, NA, NA, NA, 22300, 38380, NA,… #> $ X13 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ X14 <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"… #> $ X15 <dbl> 1477895811, 682138871, 6015539696, 2169240202, 1489645187, 8774836… #> $ X16 <dbl> 10447360, 61658258, 29159492, 22877180, 1718484, 32509, 17349847, … #> $ X17 <dbl> 41.91587, 46.29464, 34.35927, 40.78355, 40.17649, 18.18715, 43.667… #> $ X18 <dbl> -96.78852, -123.42446, -104.36870, -96.68866, -98.04684, -65.87119…  data_tbl <- copy_to(sc, data)  data_tbl #> # Source: spark<data> [?? x 18] #>    X1    X2    X3    X4    X5    X6    X7    X8    X9    X10     X11   X12   X13 #>    <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> #>  1 POLY… 31    039   0083… 31039 Cumi… Cumi… 06    H1    G4020    NA    NA    NA #>  2 POLY… 53    069   0151… 53069 Wahk… Wahk… 06    H1    G4020    NA    NA    NA #>  3 POLY… 35    011   0093… 35011 De B… De B… 06    H1    G4020    NA    NA    NA #>  4 POLY… 31    109   0083… 31109 Lanc… Lanc… 06    H1    G4020   339 30700    NA #>  5 POLY… 31    129   0083… 31129 Nuck… Nuck… 06    H1    G4020    NA    NA    NA #>  6 POLY… 72    085   0180… 72085 Las … Las … 13    H1    G4020   490 41980    NA #>  7 POLY… 46    099   0126… 46099 Minn… Minn… 06    H1    G4020    NA 43620    NA #>  8 POLY… 48    327   0138… 48327 Mena… Mena… 06    H1    G4020    NA    NA    NA #>  9 POLY… 06    091   0027… 06091 Sier… Sier… 06    H1    G4020    NA    NA    NA #> 10 POLY… 21    053   0051… 21053 Clin… Clin… 06    H1    G4020    NA    NA    NA #> # … with more rows, and 5 more variables: X14 <chr>, X15 <dbl>, X16 <dbl>, #> #   X17 <dbl>, X18 <dbl>  data_tbl %>%    transmute(geometry = st_geomfromtext(X1)) %>%    sdf_schema() #> $geometry #> $geometry$name #> [1] \"geometry\" #>  #> $geometry$type #> [1] \"GeometryUDT\" data <- sf::st_read(\"../../binder/data/testPolygon.json\") #> Reading layer `testPolygon' from data source  #>   `/Users/gregoireleleu/WORK/MISC_CODE/sedona/binder/data/testPolygon.json'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 10 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -87.62176 ymin: 34.83143 xmax: -87.60367 ymax: 34.87344 #> Geodetic CRS:  WGS 84  data %>% glimpse() #> Rows: 1 #> Columns: 11 #> $ STATEFP  <chr> \"01\" #> $ COUNTYFP <chr> \"077\" #> $ TRACTCE  <chr> \"011501\" #> $ BLKGRPCE <chr> \"5\" #> $ AFFGEOID <chr> \"1500000US010770115015\" #> $ GEOID    <chr> \"010770115015\" #> $ NAME     <chr> \"5\" #> $ LSAD     <chr> \"BG\" #> $ ALAND    <int> 6844991 #> $ AWATER   <int> 32636 #> $ geometry <POLYGON [°]> POLYGON ((-87.62176 34.8734...  data_tbl <-    copy_to(     sc,      data %>%      mutate(geometry_wkb = geometry %>% sf::st_as_text()) %>%      sf::st_drop_geometry(),   name = \"data\",   overwrite = TRUE )  data_tbl %>%    transmute(geometry = st_geomfromtext(geometry_wkb)) %>%    sdf_schema() #> $geometry #> $geometry$name #> [1] \"geometry\" #>  #> $geometry$type #> [1] \"GeometryUDT\""},{"path":"/articles/apache-sedona.html","id":"loading-directly-in-spark","dir":"Articles","previous_headings":"dplyr workflows > Loading data","what":"Loading directly in Spark","title":"Introduction to Apache Sedona for R","text":"Loading data R copying Spark likely optimal method prepare data analysis, loading data directly Spark often best. collection spark_read_* functions made purpose (extend spark_read_* functions sparklyr).","code":"data_tbl <- spark_read_geojson(sc, path = \"../../binder/data/testPolygon.json\", name = \"data\")  data_tbl %>%    glimpse() #> Rows: ?? #> Columns: 11 #> Database: spark_connection #> $ geometry <list> <<environment: 0x11e1ca0f0>>, <<environment: 0x11debb468>>, … #> $ STATEFP  <chr> \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"… #> $ COUNTYFP <chr> \"077\", \"045\", \"055\", \"089\", \"069\", \"073\", \"101\", \"015\", \"069\"… #> $ TRACTCE  <chr> \"011501\", \"021102\", \"001300\", \"001700\", \"041400\", \"010801\", \"… #> $ BLKGRPCE <chr> \"5\", \"4\", \"3\", \"2\", \"1\", \"4\", \"3\", \"1\", \"2\", \"3\", \"2\", \"4\", \"… #> $ AFFGEOID <chr> \"1500000US010770115015\", \"1500000US010450211024\", \"1500000US0… #> $ GEOID    <chr> \"010770115015\", \"010450211024\", \"010550013003\", \"010890017002… #> $ NAME     <chr> \"5\", \"4\", \"3\", \"2\", \"1\", \"4\", \"3\", \"1\", \"2\", \"3\", \"2\", \"4\", \"… #> $ LSAD     <chr> \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"BG\", \"… #> $ ALAND    <chr> \"6844991\", \"11360854\", \"1378742\", \"1040641\", \"8243574\", \"1303… #> $ AWATER   <chr> \"32636\", \"0\", \"247387\", \"0\", \"0\", \"9989\", \"0\", \"0\", \"159228\",…"},{"path":"/articles/apache-sedona.html","id":"manipulating","dir":"Articles","previous_headings":"dplyr workflows","what":"Manipulating","title":"Introduction to Apache Sedona for R","text":"dbplyr interface transparently translates dbplyr worklfows SQL, gives access Apache Sedona SQL functions: Vector functions Vector predicates Vector aggregate functions Raster operators Results collected back R collect. Geometries need converted serializable (text binary) format collect called:","code":"## ! ST_FlipCoordinates needs to be called before st_transform as by default, this function uses lat/lon order data_tbl %>%    mutate(     ALAND = ALAND %>% as.numeric(),     AWATER = AWATER %>% as.numeric(),     area = ALAND + AWATER,     geometry_proj = st_transform(ST_FlipCoordinates(geometry), \"epsg:4326\", \"epsg:5070\", TRUE),     area_geom = st_area(geometry_proj)     ) %>%    select(STATEFP, COUNTYFP, area, area_geom) %>%    head() %>%    collect() #> # A tibble: 6 × 4 #>   STATEFP COUNTYFP     area area_geom #>   <chr>   <chr>       <dbl>     <dbl> #> 1 01      077       6877627  6885810. #> 2 01      045      11360854 11372509. #> 3 01      055       1626129  1615070. #> 4 01      089       1040641  1072135. #> 5 01      069       8243574  8250531. #> 6 01      073       1313587  1302813. ## Setting the CRS in R post-collect data_tbl %>%    mutate(     area = st_area(st_transform(ST_FlipCoordinates(geometry), \"epsg:4326\", \"epsg:5070\", TRUE)),     geometry_wkb = geometry %>% st_asBinary()     ) %>%    select(COUNTYFP, geometry_wkb) %>%    head() %>%    collect() %>%    sf::st_as_sf(crs = 4326) #> Simple feature collection with 6 features and 1 field #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -87.62176 ymin: 31.22179 xmax: -85.33003 ymax: 34.87344 #> Geodetic CRS:  WGS 84 #> # A tibble: 6 × 2 #>   COUNTYFP                                                          geometry_wkb #> * <chr>                                                            <POLYGON [°]> #> 1 077      ((-87.62176 34.87344, -87.61754 34.87337, -87.6123 34.87334, -87.604… #> 2 045      ((-85.71902 31.2979, -85.71563 31.3052, -85.71427 31.3071, -85.69999… #> 3 055      ((-86.00069 34.00537, -85.99884 34.00977, -85.99801 34.0104, -85.987… #> 4 089      ((-86.57417 34.72738, -86.56268 34.72713, -86.5628 34.72387, -86.562… #> 5 069      ((-85.38287 31.23477, -85.37651 31.2347, -85.37143 31.23569, -85.365… #> 6 073      ((-86.77326 33.49818, -86.77416 33.49972, -86.77005 33.50257, -86.77… ## Setting the CRS in Spark (and using EWKT to keep it) data_tbl %>%    mutate(     area = st_area(st_transform(ST_FlipCoordinates(geometry), \"epsg:4326\", \"epsg:5070\", TRUE)),     geometry_ewkt = geometry %>% st_setsrid(4326) %>% st_asewkt()     ) %>%    select(COUNTYFP, geometry_ewkt) %>%    head() %>%    collect() %>%    sf::st_as_sf(wkt = \"geometry_ewkt\")  #> Simple feature collection with 6 features and 1 field #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -87.62176 ymin: 31.22179 xmax: -85.33003 ymax: 34.87344 #> Geodetic CRS:  WGS 84 #> # A tibble: 6 × 2 #>   COUNTYFP                                                         geometry_ewkt #>   <chr>                                                            <POLYGON [°]> #> 1 077      ((-87.62176 34.87344, -87.61754 34.87337, -87.6123 34.87334, -87.604… #> 2 045      ((-85.71902 31.2979, -85.71563 31.3052, -85.71427 31.3071, -85.69999… #> 3 055      ((-86.00069 34.00537, -85.99884 34.00977, -85.99801 34.0104, -85.987… #> 4 089      ((-86.57417 34.72738, -86.56268 34.72713, -86.5628 34.72387, -86.562… #> 5 069      ((-85.38287 31.23477, -85.37651 31.2347, -85.37143 31.23569, -85.365… #> 6 073      ((-86.77326 33.49818, -86.77416 33.49972, -86.77005 33.50257, -86.77…"},{"path":"/articles/apache-sedona.html","id":"writing","dir":"Articles","previous_headings":"dplyr workflows","what":"Writing","title":"Introduction to Apache Sedona for R","text":"Collected results can saved directly R. many cases efficient write results directly Spark. spark_write_* (see docs) functions made purpose (extend spark_write_* functions sparklyr). output can partitioned columns present data:","code":"dest_file <- tempfile() ## Destination folder data_tbl %>%    filter(str_sub(COUNTYFP, 1, 2) == \"00\") %>%    spark_write_geoparquet(path = dest_file)  dest_file %>% dir(recursive = TRUE) #> [1] \"_SUCCESS\"                                                            #> [2] \"part-00000-8eea1db8-d140-41c1-ac76-1aa13f2b49c9-c000.snappy.parquet\" dest_file <- tempfile()  ## Destination folder data_tbl %>%    filter(str_sub(COUNTYFP, 1, 2) == \"00\") %>%    spark_write_geoparquet(path = dest_file, partition_by = \"COUNTYFP\")  dest_file %>% dir(recursive = TRUE) #> [1] \"_SUCCESS\"                                                                         #> [2] \"COUNTYFP=001/part-00000-3033294e-0bad-40cf-a7cc-5e56030a3b04.c000.snappy.parquet\" #> [3] \"COUNTYFP=003/part-00000-3033294e-0bad-40cf-a7cc-5e56030a3b04.c000.snappy.parquet\" #> [4] \"COUNTYFP=005/part-00000-3033294e-0bad-40cf-a7cc-5e56030a3b04.c000.snappy.parquet\" #> [5] \"COUNTYFP=007/part-00000-3033294e-0bad-40cf-a7cc-5e56030a3b04.c000.snappy.parquet\" #> [6] \"COUNTYFP=009/part-00000-3033294e-0bad-40cf-a7cc-5e56030a3b04.c000.snappy.parquet\""},{"path":"/articles/apache-sedona.html","id":"spark-dataframes","dir":"Articles","previous_headings":"dplyr workflows","what":"Spark DataFrames","title":"Introduction to Apache Sedona for R","text":"Spark DataFrames provide higher level API RDDs, can used SQL queries. sparklyr apache.sedona automatically wrap Spark DataFrames dplyr tbls work dplyr workflows. can get underlying Spark DataFrame (SDF) sparklyr::spark_dataframe","code":"data_tbl %>% class() #> [1] \"tbl_spark\" \"tbl_sql\"   \"tbl_lazy\"  \"tbl\" sdf <- data_tbl %>% spark_dataframe() sdf #> <jobj[161]> #>   org.apache.spark.sql.Dataset #>   [geometry: geometry, STATEFP: string ... 9 more fields]"},{"path":[]},{"path":"/articles/apache-sedona.html","id":"what-are-spatialrdds","dir":"Articles","previous_headings":"RDD workflows","what":"What are SpatialRDDs?","title":"Introduction to Apache Sedona for R","text":"SpatialRDDs basic building blocks distributed spatial data Apache Sedona. SpatialRDD can partitioned indexed using well-known spatial data structures facilitate range queries, KNN queries, low-level operations. One can also export records SpatialRDDs regular Spark DataFrames, making accessible Spark SQL dplyr interface sparklyr.","code":""},{"path":"/articles/apache-sedona.html","id":"creating-a-spatialrdd","dir":"Articles","previous_headings":"RDD workflows","what":"Creating a SpatialRDD","title":"Introduction to Apache Sedona for R","text":"NOTE: section largely based Spatial RDD Scala tutorial, except examples written R instead Scala reflect usages apache.sedona. Currently SpatialRDDs can created apache.sedona reading file supported geospatial format (sedona_read_* functions), extracting data Spark SQL query. example, following code import data arealm-small.csv SpatialRDD: Records example arealm-small.csv file look like following: one can see , record comma-separated consists 2-dimensional coordinate starting 2nd column ending 3rd column. columns contain non-spatial attributes. column indexes 0-based, need specify first_spatial_col_index = 1 example ensure record parsed correctly. addition formats CSV TSV, currently apache.sedona also supports reading files WKT (Well-Known Text), WKB (Well-Known Binary), Shapefile GeoJSON formats. See sedona_read_wkt details.","code":"pt_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = \"../../binder/data/arealm-small.csv\",   delimiter = \",\",   type = \"point\",   first_spatial_col_index = 1,   has_non_spatial_attrs = TRUE ) testattribute0,-88.331492,32.324142,testattribute1,testattribute2 testattribute0,-88.175933,32.360763,testattribute1,testattribute2 testattribute0,-88.388954,32.357073,testattribute1,testattribute2"},{"path":"/articles/apache-sedona.html","id":"conversion-to-and-from-spatialrdd","dir":"Articles","previous_headings":"RDD workflows","what":"Conversion to and from SpatialRDD","title":"Introduction to Apache Sedona for R","text":"One can also run to_spatial_rdd() extract SpatialRDD Spark SQL query, e.g. query extract spatial column named \"geom\" Sedona spatial SQL query store SpatialRDD object. SpatialRDD can converted Spark DataFrame sdf_register (generic method sparklyr).","code":"library(dplyr)  sdf <- tbl(   sc,   sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `geom`, \\\"point\\\" AS `type`\") )  spatial_rdd <- sdf %>% to_spatial_rdd(spatial_col = \"geom\") spatial_rdd #> $.jobj #> <jobj[169]> #>   org.apache.sedona.core.spatialRDD.SpatialRDD #>   org.apache.sedona.core.spatialRDD.SpatialRDD@13d814f #>  #> $.state #> <environment: 0x12d5d5340> #>  #> attr(,\"class\") #> [1] \"spatial_rdd\" spatial_sdf <- spatial_rdd %>% sdf_register(name = \"my_table\") spatial_sdf #> # Source: spark<my_table> [?? x 2] #>   geometry                      type  #>   <list>                        <chr> #> 1 <POINT (-71.064544 42.28787)> point"},{"path":"/articles/apache-sedona.html","id":"visualization","dir":"Articles","previous_headings":"","what":"Visualization","title":"Introduction to Apache Sedona for R","text":"important part apache.sedona collection R interfaces Sedona visualization routines. example, following essentially R equivalent example Scala. create scatter plot, overlay top choropleth map, shown :  See ?apache.sedona::sedona_render_scatter_plot, ?apache.sedona::sedona_render_heatmap, ?apache.sedona::sedona_render_choropleth_map details visualization-related R interfaces currently implemented apache.sedona.","code":"resolution_x <- 1000 resolution_y <- 600 boundary <- c(-126.790180, -64.630926, 24.863836, 50.000)  pt_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = \"../../core/src/test/resources/arealm.csv\",   type = \"point\" ) polygon_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = \"../../core/src/test/resources/primaryroads-polygon.csv\",   type = \"polygon\" ) pair_rdd <- sedona_spatial_join_count_by_key(   pt_rdd,   polygon_rdd,   join_type = \"intersect\" )  overlay <- sedona_render_scatter_plot(   polygon_rdd,   resolution_x,   resolution_y,   output_location = tempfile(\"scatter-plot-\"),   boundary = boundary,   base_color = c(255, 0, 0),   browse = FALSE )  sedona_render_choropleth_map(   pair_rdd,   resolution_x,   resolution_y,   output_location = \"./choropleth-map\",   boundary = boundary,   overlay = overlay,   # vary the green color channel according to relative magnitudes of data points so   # that the resulting map will show light blue, light purple, and light gray pixels   color_of_variation = \"green\",   base_color = c(225, 225, 255) )"},{"path":"/articles/apache-sedona.html","id":"advanced-parameters","dir":"Articles","previous_headings":"","what":"Advanced parameters","title":"Introduction to Apache Sedona for R","text":"Various advanced parameters can set Apache Sedona, see parameters sparklyr config: Check change runtime:","code":"config <- spark_config() config[[\"sedona.global.index\"]] <- FALSE  sc <- spark_connect(master = \"local\", config = config) #> ℹ Using Sedona jars listed in SEDONA_JAR_FILES variable (see Sys.getenv(\"SEDONA_JAR_FILES\")) invoke_new(sc, \"org.apache.sedona.core.utils.SedonaConf\", invoke(spark_session(sc), \"conf\"))  #> <jobj[53]> #>   org.apache.sedona.core.utils.SedonaConf #>   Sedona Configuration: #> useIndex: true #> indexType: QUADTREE #> joinSparitionDominantSide: LEFT #> joinBuildSide: LEFT #> joinApproximateTotalCount: -1 #> datasetBoundary: Env[0.0 : 0.0, 0.0 : 0.0] #> fallbackPartitionNum: -1 #> joinGridType: KDBTREE #> autoBroadcastJoinThreshold: 10485760 spark_session(sc) %>%    invoke(\"conf\") %>%    invoke(\"set\", \"sedona.global.index\",\"true\") #> NULL  invoke_new(sc, \"org.apache.sedona.core.utils.SedonaConf\", invoke(spark_session(sc), \"conf\"))  #> <jobj[57]> #>   org.apache.sedona.core.utils.SedonaConf #>   Sedona Configuration: #> useIndex: true #> indexType: QUADTREE #> joinSparitionDominantSide: LEFT #> joinBuildSide: LEFT #> joinApproximateTotalCount: -1 #> datasetBoundary: Env[0.0 : 0.0, 0.0 : 0.0] #> fallbackPartitionNum: -1 #> joinGridType: KDBTREE #> autoBroadcastJoinThreshold: 10485760"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Apache Sedona. Author, maintainer. Jia Yu. Contributor, copyright holder. Yitao Li. Author, copyright holder. Apache Software Foundation. Copyright holder. RStudio. Copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Apache Sedona, Li Y (2023). apache.sedona: R Interface Apache Sedona. https://github.com/apache/sedona/, https://sedona.apache.org/.","code":"@Manual{,   title = {apache.sedona: R Interface for Apache Sedona},   author = {{Apache Sedona} and Yitao Li},   year = {2023},   note = {https://github.com/apache/sedona/, https://sedona.apache.org/}, }"},{"path":"/index.html","id":"apachesedona-","dir":"","previous_headings":"","what":"R Interface for Apache Sedona","title":"R Interface for Apache Sedona","text":"Apache Sedona cluster computing system processing large-scale spatial data. Sedona extends existing cluster computing systems, Apache Spark Apache Flink, set ---box distributed Spatial Datasets Spatial SQL efficiently load, process, analyze large-scale spatial data across machines. apache.sedona R package exposes interface Apache Sedona sparklyr enabling higher-level access dplyr backend familiar R functions.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Interface for Apache Sedona","text":"use Apache Sedona R, just need install apache.sedona package; Spark dependencies managed directly package.","code":"# Install released version from CRAN install.packages(\"apache.sedona\")"},{"path":"/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"R Interface for Apache Sedona","text":"use development version, need latest version package Apache Sedona jars. get latest R package GtiHub: get latest Sedona jars can: Compile Sedona code , see Compile code Get latest generated jars GitHub ‘Java build’ action; click latest run, generated jars bottom page path sedona-spark-shaded sedona-viz jars needs put SEDONA_JAR_FILES environment variables (see ).","code":"# Install development version from GitHub devtools::install_github(\"apache/sedona/R\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"R Interface for Apache Sedona","text":"spark_read_* functions read geospatial data Spark Dataframes. resulting Spark dataframe object can modified using dplyr verbs familiar many R users. addition, spatial UDFs supported Sedona can inter-operate seamlessly functions supported sparklyr’s dbplyr SQL translation env. example, code finds average area polygons polygon_sdf: first Notice can open many interesting possiblities. example, one can extract ML features geospatial data Spark dataframes, build ML pipeline using ml_* family functions sparklyr work features, output ML model happens geospatial object well, one can even apply visualization routines apache.sedona visualize difference predicted geometry corresponding ground truth.","code":"library(sparklyr) library(apache.sedona)  ## Only if using development version: Sys.setenv(\"SEDONA_JAR_FILES\" = \"<path to sedona-spark-shaded jar>:<path to sedona-viz jar>\")  sc <- spark_connect(master = \"local\") polygon_sdf <- spark_read_geojson(sc, location = \"/tmp/polygon.json\") mean_area_sdf <- polygon_sdf %>%   dplyr::summarize(mean_area = mean(ST_Area(geometry))) print(mean_area_sdf)"},{"path":"/reference/apache.sedona-package.html","id":null,"dir":"Reference","previous_headings":"","what":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","title":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","text":"R interface 'Apache Sedona' based 'sparklyr' (https://sedona.apache.org).","code":""},{"path":[]},{"path":"/reference/apache.sedona-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","text":"Maintainer:  Apache Sedona private@sedona.apache.org Authors: Yitao Li yitao@rstudio.com (ORCID) [copyright holder] contributors: Jia Yu jiayu@apache.org [contributor, copyright holder] Apache Software Foundation [copyright holder] RStudio [copyright holder]","code":""},{"path":"/reference/approx_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the approximate total number of records within a Spatial RDD. — approx_count","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"Given Sedona spatial RDD, find (possibly approximated) number total records within .","code":""},{"path":"/reference/approx_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"","code":"approx_count(x)"},{"path":"/reference/approx_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/approx_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"Approximate number records within SpatialRDD.","code":""},{"path":[]},{"path":"/reference/approx_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"","code":"library(sparklyr) #>  #> Attaching package: ‘sparklyr’ #> The following object is masked from ‘package:stats’: #>  #>     filter library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   approx_cnt <- approx_count(rdd) }"},{"path":"/reference/as.spark.dataframe.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","title":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","text":"Import data spatial RDD (possibly non-spatial attributes) Spark Dataframe.","code":""},{"path":"/reference/as.spark.dataframe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","text":"","code":"as.spark.dataframe(x, non_spatial_cols = NULL, name = NULL)"},{"path":"/reference/as.spark.dataframe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","text":"x spatial RDD. non_spatial_cols Column names non-spatial attributes resulting Spark Dataframe. default (NULL) import field names property exists, particular shapefiles. name Name assign resulting Spark temporary view. unspecified, random name assigned.","code":""},{"path":"/reference/as.spark.dataframe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","text":"Spark Dataframe containing imported spatial data.","code":""},{"path":"/reference/as.spark.dataframe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data from a spatial RDD into a Spark Dataframe. — as.spark.dataframe","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L,     repartition = 5   )   sdf <- as.spark.dataframe(rdd, non_spatial_cols = c(\"attr1\", \"attr2\")) }"},{"path":"/reference/as_spark_dataframe.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from a spatial RDD into a Spark Dataframe. — as_spark_dataframe","title":"Import data from a spatial RDD into a Spark Dataframe. — as_spark_dataframe","text":"Import data spatial RDD Spark Dataframe.","code":""},{"path":"/reference/as_spark_dataframe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from a spatial RDD into a Spark Dataframe. — as_spark_dataframe","text":"x spatial RDD. name Name assign resulting Spark temporary view. unspecified, random name assigned.","code":""},{"path":"/reference/crs_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a CRS transformation. — crs_transform","title":"Perform a CRS transformation. — crs_transform","text":"Transform data within spatial RDD one coordinate reference system another.","code":""},{"path":"/reference/crs_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a CRS transformation. — crs_transform","text":"","code":"crs_transform(x, src_epsg_crs_code, dst_epsg_crs_code, strict = FALSE)"},{"path":"/reference/crs_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a CRS transformation. — crs_transform","text":"x spatial RDD processed. src_epsg_crs_code Coordinate reference system transform (e.g., \"epsg:4326\", \"epsg:3857\", etc). dst_epsg_crs_code Coordinate reference system transform . (e.g., \"epsg:4326\", \"epsg:3857\", etc). strict FALSE (default), ignore \"Bursa-Wolf Parameters Required\" error.","code":""},{"path":"/reference/crs_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a CRS transformation. — crs_transform","text":"transformed SpatialRDD.","code":""},{"path":"/reference/crs_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a CRS transformation. — crs_transform","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   crs_transform(     rdd,     src_epsg_crs_code = \"epsg:4326\", dst_epsg_crs_code = \"epsg:3857\"   ) }"},{"path":"/reference/minimum_bounding_box.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the minimal bounding box of a geometry. — minimum_bounding_box","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"Given Sedona spatial RDD, find axis-aligned minimal bounding box geometry represented RDD.","code":""},{"path":"/reference/minimum_bounding_box.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"","code":"minimum_bounding_box(x)"},{"path":"/reference/minimum_bounding_box.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/minimum_bounding_box.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"minimum bounding box object.","code":""},{"path":[]},{"path":"/reference/minimum_bounding_box.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   boundary <- minimum_bounding_box(rdd) }"},{"path":"/reference/new_bounding_box.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a bounding box object. — new_bounding_box","title":"Construct a bounding box object. — new_bounding_box","text":"Construct axis-aligned rectangular bounding box object.","code":""},{"path":"/reference/new_bounding_box.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a bounding box object. — new_bounding_box","text":"","code":"new_bounding_box(sc, min_x = -Inf, max_x = Inf, min_y = -Inf, max_y = Inf)"},{"path":"/reference/new_bounding_box.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a bounding box object. — new_bounding_box","text":"sc Spark connection. min_x Minimum x-value bounding box, can +/- Inf. max_x Maximum x-value bounding box, can +/- Inf. min_y Minimum y-value bounding box, can +/- Inf. max_y Maximum y-value bounding box, can +/- Inf.","code":""},{"path":"/reference/new_bounding_box.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a bounding box object. — new_bounding_box","text":"bounding box object.","code":""},{"path":"/reference/new_bounding_box.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a bounding box object. — new_bounding_box","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\") bb <- new_bounding_box(sc, -1, 1, -1, 1)"},{"path":"/reference/sdf_register.spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"Import data spatial RDD (possibly non-spatial attributes) Spark Dataframe. sdf_register: method sparklyr's sdf_register handle Spatial RDD .spark.dataframe: lower level function fine-grained control non-spatial columns","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"","code":"# S3 method for spatial_rdd sdf_register(x, name = NULL)  as.spark.dataframe(x, non_spatial_cols = NULL, name = NULL)"},{"path":"/reference/sdf_register.spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"x spatial RDD. name Name assign resulting Spark temporary view. unspecified, random name assigned. non_spatial_cols Column names non-spatial attributes resulting Spark Dataframe. default (NULL) import field names property exists, particular shapefiles.","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"Spark Dataframe containing imported spatial data.","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   sdf <- sdf_register(rdd)      input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L,     repartition = 5   )   sdf <- as.spark.dataframe(rdd, non_spatial_cols = c(\"attr1\", \"attr2\")) }"},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"Given Sedona spatial RDD, partition content using spatial partitioner.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"","code":"sedona_apply_spatial_partitioner(   rdd,   partitioner = c(\"quadtree\", \"kdbtree\"),   max_levels = NULL )"},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"rdd spatial RDD partitioned. partitioner name grid type use (currently \"quadtree\" \"kdbtree\" supported) org.apache.sedona.core.spatialPartitioning.SpatialPartitioner JVM object. latter option relevant advanced use cases involving custom spatial partitioner. max_levels Maximum number levels partitioning tree data structure. NULL (default), use current number partitions within rdd maximum number levels. Specifying max_levels unsupported use cases involving custom spatial partitioner scenarios partitioner object already maximum number levels set well-defined way override existing setting partitioning data structure.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"spatially partitioned SpatialRDD.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   sedona_apply_spatial_partitioner(rdd, partitioner = \"kdbtree\") }"},{"path":"/reference/sedona_build_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an index on a Sedona spatial RDD. — sedona_build_index","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"Given Sedona spatial RDD, build type index specified partition(s).","code":""},{"path":"/reference/sedona_build_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"","code":"sedona_build_index(   rdd,   type = c(\"quadtree\", \"rtree\"),   index_spatial_partitions = TRUE )"},{"path":"/reference/sedona_build_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"rdd spatial RDD indexed. type type index build. Currently \"quadtree\" \"rtree\" supported. index_spatial_partitions RDD already partitioned using spatial partitioner, index spatial partition within RDD instead partitions within raw RDD associated underlying spatial data source. Default: TRUE. Notice option irrelevant input RDD partitioned using spatial partitioner yet.","code":""},{"path":"/reference/sedona_build_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"spatial index object.","code":""},{"path":"/reference/sedona_build_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   sedona_build_index(rdd, type = \"rtree\") }"},{"path":"/reference/sedona_knn_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the k nearest spatial objects. — sedona_knn_query","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"Given spatial RDD, query object x, integer k, find k nearest spatial objects within RDD x (distance x another geometrical object measured minimum possible length line segment connecting 2 objects).","code":""},{"path":"/reference/sedona_knn_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"","code":"sedona_knn_query(   rdd,   x,   k,   index_type = c(\"quadtree\", \"rtree\"),   result_type = c(\"rdd\", \"sdf\", \"raw\") )"},{"path":"/reference/sedona_knn_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"rdd Sedona spatial RDD. x query object. k Number nearest spatail objects return. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/sedona_knn_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"KNN query result.","code":""},{"path":[]},{"path":"/reference/sedona_knn_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   knn_query_pt_x <- -84.01   knn_query_pt_y <- 34.01   knn_query_pt_tbl <- sdf_sql(     sc,     sprintf(       \"SELECT ST_GeomFromText(\\\"POINT(%f %f)\\\") AS `pt`\",       knn_query_pt_x,       knn_query_pt_y     )   ) %>%       collect()   knn_query_pt <- knn_query_pt_tbl$pt[[1]]   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   knn_result_sdf <- sedona_knn_query(     rdd,     x = knn_query_pt, k = 3, index_type = \"rtree\", result_type = \"sdf\"   ) }"},{"path":"/reference/sedona_range_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a range query. — sedona_range_query","title":"Execute a range query. — sedona_range_query","text":"Given spatial RDD query object x, find spatial objects within RDD covered x intersect x.","code":""},{"path":"/reference/sedona_range_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a range query. — sedona_range_query","text":"","code":"sedona_range_query(   rdd,   x,   query_type = c(\"cover\", \"intersect\"),   index_type = c(\"quadtree\", \"rtree\"),   result_type = c(\"rdd\", \"sdf\", \"raw\") )"},{"path":"/reference/sedona_range_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a range query. — sedona_range_query","text":"rdd Sedona spatial RDD. x query object. query_type Type spatial relationship involved query. Currently \"cover\" \"intersect\" supported. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/sedona_range_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute a range query. — sedona_range_query","text":"range query result.","code":""},{"path":[]},{"path":"/reference/sedona_range_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute a range query. — sedona_range_query","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   range_query_min_x <- -87   range_query_max_x <- -50   range_query_min_y <- 34   range_query_max_y <- 54   geom_factory <- invoke_new(     sc,     \"org.locationtech.jts.geom.GeometryFactory\"   )   range_query_polygon <- invoke_new(     sc,     \"org.locationtech.jts.geom.Envelope\",     range_query_min_x,     range_query_max_x,     range_query_min_y,     range_query_max_y   ) %>%     invoke(geom_factory, \"toGeometry\", .)   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   range_query_result_sdf <- sedona_range_query(     rdd,     x = range_query_polygon,     query_type = \"intersect\",     index_type = \"rtree\",     result_type = \"sdf\"   ) }"},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"Create typed SpatialRDD (namely, PointRDD, PolygonRDD, LineStringRDD) data source containing delimiter-separated values. data source can contain spatial attributes (e.g., longitude latidude) attributes. Currently inputs spatial attributes occupying contiguous range columns (.e., [first_spatial_col_index, last_spatial_col_index]) supported.","code":""},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"","code":"sedona_read_dsv_to_typed_rdd(   sc,   location,   delimiter = c(\",\", \"\\t\", \"?\", \"'\", \"\\\"\", \"_\", \"-\", \"%\", \"~\", \"|\", \";\"),   type = c(\"point\", \"polygon\", \"linestring\"),   first_spatial_col_index = 0L,   last_spatial_col_index = NULL,   has_non_spatial_attrs = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"sc spark_connection. location Location data source. delimiter Delimiter within record. Must one ',', '\\t', '?', '\\'', '\"', '_', '-', '%', '~', '|', ';' type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". first_spatial_col_index Zero-based index left-column containing spatial attributes (default: 0). last_spatial_col_index Zero-based index right-column containing spatial attributes (default: NULL). Note last_spatial_col_index need specified creating PointRDD automatically implied value (first_spatial_col_index + 1). types RDDs, last_spatial_col_index unspecified, assume value -1 (.e., last input columns). has_non_spatial_attrs Whether input contains non-spatial attributes. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"typed SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your csv file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   ) }"},{"path":"/reference/sedona_read_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Read geospatial data into a Spatial RDD — sedona_read_geojson","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"Import spatial object external data source Sedona SpatialRDD. sedona_read_shapefile: shapefile sedona_read_geojson: geojson file sedona_read_wkt: geojson file sedona_read_wkb: geojson file","code":""},{"path":"/reference/sedona_read_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"","code":"sedona_read_geojson(   sc,   location,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_wkb(   sc,   location,   wkb_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_wkt(   sc,   location,   wkt_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_shapefile(sc, location, storage_level = \"MEMORY_ONLY\")"},{"path":"/reference/sedona_read_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"sc spark_connection. location Location data source. allow_invalid_geometries Whether allow topology-invalid geometries exist resulting RDD. skip_syntactically_invalid_geometries Whether allows Sedona automatically skip syntax-invalid geometries, rather throwing errorings. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1). type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". has_non_spatial_attrs Whether input contains non-spatial attributes.","code":""},{"path":"/reference/sedona_read_geojson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson(sc, location = input_location) }"},{"path":"/reference/sedona_read_geojson_to_typed_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","title":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","text":"Constructors typed RDD (PointRDD, PolygonRDD, LineStringRDD) soft deprecated, use non-types versions Create typed SpatialRDD (namely, PointRDD, PolygonRDD, LineStringRDD) GeoJSON data source.","code":""},{"path":"/reference/sedona_read_geojson_to_typed_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","text":"","code":"sedona_read_geojson_to_typed_rdd(   sc,   location,   type = c(\"point\", \"polygon\", \"linestring\"),   has_non_spatial_attrs = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_geojson_to_typed_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","text":"sc spark_connection. location Location data source. type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". has_non_spatial_attrs Whether input contains non-spatial attributes. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_geojson_to_typed_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","text":"typed SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_geojson_to_typed_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a typed SpatialRDD from a GeoJSON data source. — sedona_read_geojson_to_typed_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   ) }"},{"path":"/reference/sedona_read_shapefile.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","title":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","text":"Create generic SpatialRDD shapefile data source.","code":""},{"path":"/reference/sedona_read_shapefile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","text":"","code":"sedona_read_shapefile(sc, location, storage_level = \"MEMORY_ONLY\")"},{"path":"/reference/sedona_read_shapefile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","text":"sc spark_connection. location Location data source. storage_level Storage level RDD (default: MEMORY_ONLY).","code":""},{"path":"/reference/sedona_read_shapefile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","text":"SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_shapefile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a SpatialRDD from a shapefile data source. — sedona_read_shapefile","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile(sc, location = input_location) }"},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"Constructors typed RDD (PointRDD, PolygonRDD, LineStringRDD) soft deprecated, use non-types versions Create typed SpatialRDD (namely, PointRDD, PolygonRDD, LineStringRDD) sedona_read_shapefile_to_typed_rdd: shapefile data source sedona_read_geojson_to_typed_rdd: GeoJSON data source","code":""},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"","code":"sedona_read_shapefile_to_typed_rdd(   sc,   location,   type = c(\"point\", \"polygon\", \"linestring\"),   storage_level = \"MEMORY_ONLY\" )  sedona_read_geojson_to_typed_rdd(   sc,   location,   type = c(\"point\", \"polygon\", \"linestring\"),   has_non_spatial_attrs = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"sc spark_connection. location Location data source. type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". storage_level Storage level RDD (default: MEMORY_ONLY). has_non_spatial_attrs Whether input contains non-spatial attributes. repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"typed SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your shapefile   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   ) }"},{"path":"/reference/sedona_read_wkb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","title":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","text":"Create generic SpatialRDD hex-encoded Well-Known Binary (WKB) data source.","code":""},{"path":"/reference/sedona_read_wkb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","text":"","code":"sedona_read_wkb(   sc,   location,   wkb_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_wkb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","text":"sc spark_connection. location Location data source. wkb_col_idx Zero-based index column containing hex-encoded WKB data (default: 0). allow_invalid_geometries Whether allow topology-invalid geometries exist resulting RDD. skip_syntactically_invalid_geometries Whether allows Sedona automatically skip syntax-invalid geometries, rather throwing errorings. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_wkb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","text":"SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_wkb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a SpatialRDD from a Well-Known Binary (WKB) data source. — sedona_read_wkb","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_wkb(     sc,     location = input_location, wkb_col_idx = 0L   ) }"},{"path":"/reference/sedona_read_wkt.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","title":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","text":"Create generic SpatialRDD Well-Known Text (WKT) data source.","code":""},{"path":"/reference/sedona_read_wkt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","text":"","code":"sedona_read_wkt(   sc,   location,   wkt_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_wkt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","text":"sc spark_connection. location Location data source. wkt_col_idx Zero-based index column containing hex-encoded WKB data (default: 0). allow_invalid_geometries Whether allow topology-invalid geometries exist resulting RDD. skip_syntactically_invalid_geometries Whether allows Sedona automatically skip syntax-invalid geometries, rather throwing errorings. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_wkt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","text":"SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_wkt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a SpatialRDD from a Well-Known Text (WKT) data source. — sedona_read_wkt","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(\"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_wkt(     sc,     location = input_location,     wkt_col_idx = 0L   ) }"},{"path":"/reference/sedona_render_choropleth_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"Generate choropleth map pair RDD assigning integral values polygons.","code":""},{"path":"/reference/sedona_render_choropleth_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"","code":"sedona_render_choropleth_map(   pair_rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   color_of_variation = c(\"red\", \"green\", \"blue\"),   base_color = c(0, 0, 0),   shade = TRUE,   reverse_coords = FALSE,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_choropleth_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"pair_rdd pair RDD Sedona Polygon objects keys java.lang.Long values. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. reverse_coords Whether reverse spatial coordinates plot (default: FALSE). overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_choropleth_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_choropleth_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   pt_input_location <- \"/dev/null\" # replace it with the path to your input file   pt_rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = pt_input_location,     type = \"point\",     first_spatial_col_index = 1   )   polygon_input_location <- \"/dev/null\" # replace it with the path to your input file   polygon_rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = polygon_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join_count_by_key(     pt_rdd,     polygon_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   )   sedona_render_choropleth_map(     join_result_rdd,     400,     200,     output_location = tempfile(\"choropleth-map-\"),     boundary = c(-86.8, -86.6, 33.4, 33.6),     base_color = c(255, 255, 255)   ) }"},{"path":"/reference/sedona_render_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"Generate heatmap geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_render_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"","code":"sedona_render_heatmap(   rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   blur_radius = 10L,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. blur_radius Controls radius Gaussian blur resulting heatmap. overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     type = \"point\"   )    sedona_render_heatmap(     rdd,     resolution_x = 800,     resolution_y = 600,     output_location = tempfile(\"points-\"),     output_format = \"png\",     boundary = c(-91, -84, 30, 35),     blur_radius = 10   ) }"},{"path":"/reference/sedona_render_scatter_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"Generate scatter plot geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_render_scatter_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"","code":"sedona_render_scatter_plot(   rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   color_of_variation = c(\"red\", \"green\", \"blue\"),   base_color = c(0, 0, 0),   shade = TRUE,   reverse_coords = FALSE,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_scatter_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. reverse_coords Whether reverse spatial coordinates plot (default: FALSE). overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_scatter_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_scatter_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     type = \"point\"   )    sedona_render_scatter_plot(     rdd,     resolution_x = 800,     resolution_y = 600,     output_location = tempfile(\"points-\"),     output_format = \"png\",     boundary = c(-91, -84, 30, 35)   ) }"},{"path":"/reference/sedona_save_spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"Export serialized data Spark dataframe containing exactly 1 spatial column file.","code":""},{"path":"/reference/sedona_save_spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"","code":"sedona_save_spatial_rdd(   x,   spatial_col,   output_location,   output_format = c(\"wkb\", \"wkt\", \"geojson\") )"},{"path":"/reference/sedona_save_spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"x Spark dataframe object sparklyr dplyr expression representing Spark SQL query. spatial_col name spatial column. output_location Location output file. output_format Format output.","code":""},{"path":"/reference/sedona_save_spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_save_spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   sedona_save_spatial_rdd(     tbl %>% dplyr::mutate(id = 1),     spatial_col = \"pt\",     output_location = \"/tmp/pts.wkb\",     output_format = \"wkb\"   ) }"},{"path":"/reference/sedona_spatial_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"Given spatial_rdd query_window_rdd, return pair RDD containing pairs geometrical elements (p, q) p element spatial_rdd, q element query_window_rdd, (p, q) satisfies spatial relation specified join_type.","code":""},{"path":"/reference/sedona_spatial_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"","code":"sedona_spatial_join(   spatial_rdd,   query_window_rdd,   join_type = c(\"contain\", \"intersect\"),   partitioner = c(\"quadtree\", \"kdbtree\"),   index_type = c(\"quadtree\", \"rtree\") )"},{"path":"/reference/sedona_spatial_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/sedona_spatial_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"spatial RDD containing join result.","code":""},{"path":[]},{"path":"/reference/sedona_spatial_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   query_rdd_input_location <- \"/dev/null\" # replace it with the path to your input file   query_rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = query_rdd_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join(     rdd,     query_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   ) }"},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"element p spatial_rdd, count number unique elements q query_window_rdd (p, q) satisfies spatial relation specified join_type.","code":""},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"","code":"sedona_spatial_join_count_by_key(   spatial_rdd,   query_window_rdd,   join_type = c(\"contain\", \"intersect\"),   partitioner = c(\"quadtree\", \"kdbtree\"),   index_type = c(\"quadtree\", \"rtree\") )"},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"spatial RDD containing join-count--key results.","code":""},{"path":[]},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   query_rdd_input_location <- \"/dev/null\" # replace it with the path to your input file   query_rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = query_rdd_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join_count_by_key(     rdd,     query_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   ) }"},{"path":"/reference/sedona_spatial_rdd_aggregation_routine.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","title":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","text":"Function extracting aggregate statistics Sedona spatial RDD.","code":""},{"path":"/reference/sedona_spatial_rdd_aggregation_routine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/sedona_spatial_rdd_data_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","title":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","text":"Import spatial object external data source Sedona SpatialRDD.","code":""},{"path":"/reference/sedona_spatial_rdd_data_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","text":"sc spark_connection. location Location data source. type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". has_non_spatial_attrs Whether input contains non-spatial attributes. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_spatial_rdd_serialization_routine.html","id":null,"dir":"Reference","previous_headings":"","what":"Write SpatialRDD into a file. — sedona_spatial_rdd_serialization_routine","title":"Write SpatialRDD into a file. — sedona_spatial_rdd_serialization_routine","text":"Export serialized data Sedona SpatialRDD output file.","code":""},{"path":"/reference/sedona_spatial_rdd_serialization_routine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write SpatialRDD into a file. — sedona_spatial_rdd_serialization_routine","text":"x SpatialRDD object. output_location Location output file.","code":""},{"path":"/reference/sedona_visualization_routines.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","title":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","text":"Generate visual representation geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_visualization_routines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_write_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","title":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","text":"Export serialized data Sedona SpatialRDD GeoJSON file.","code":""},{"path":"/reference/sedona_write_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","text":"","code":"sedona_write_geojson(x, output_location)"},{"path":"/reference/sedona_write_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","text":"x SpatialRDD object. output_location Location output file.","code":""},{"path":"/reference/sedona_write_geojson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_write_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write SpatialRDD into a GeoJSON file. — sedona_write_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   sedona_write_geojson(rdd, \"/tmp/example.json\") }"},{"path":"/reference/sedona_write_wkb.html","id":null,"dir":"Reference","previous_headings":"","what":"Write SpatialRDD into a file. — sedona_write_wkb","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"Export serialized data Sedona SpatialRDD file. sedona_write_wkb: sedona_write_wkt: sedona_write_geojson:","code":""},{"path":"/reference/sedona_write_wkb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"","code":"sedona_write_wkb(x, output_location)  sedona_write_wkt(x, output_location)  sedona_write_geojson(x, output_location)"},{"path":"/reference/sedona_write_wkb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"x SpatialRDD object. output_location Location output file.","code":""},{"path":"/reference/sedona_write_wkb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_write_wkb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_wkb(     sc,     location = input_location,     wkb_col_idx = 0L   )   sedona_write_wkb(rdd, \"/tmp/wkb_output.tsv\") }"},{"path":"/reference/sedona_write_wkt.html","id":null,"dir":"Reference","previous_headings":"","what":"Write SpatialRDD into a WKT file. — sedona_write_wkt","title":"Write SpatialRDD into a WKT file. — sedona_write_wkt","text":"Export serialized data Sedona SpatialRDD WKT file.","code":""},{"path":"/reference/sedona_write_wkt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write SpatialRDD into a WKT file. — sedona_write_wkt","text":"","code":"sedona_write_wkt(x, output_location)"},{"path":"/reference/sedona_write_wkt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write SpatialRDD into a WKT file. — sedona_write_wkt","text":"x SpatialRDD object. output_location Location output file.","code":""},{"path":"/reference/sedona_write_wkt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write SpatialRDD into a WKT file. — sedona_write_wkt","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_write_wkt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write SpatialRDD into a WKT file. — sedona_write_wkt","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(\"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_wkt(     sc,     location = input_location,     wkt_col_idx = 0L   )   sedona_write_wkt(rdd, \"/tmp/wkt_output.tsv\") }"},{"path":"/reference/spark_read_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","title":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","text":"Read geojson file Spark DataFrame. Read geojson file Spark DataFrame.","code":""},{"path":"/reference/spark_read_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","text":"","code":"spark_read_geojson(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )"},{"path":"/reference/spark_read_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","text":"sc spark_connection. name name assign newly generated table. path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. options list strings additional options. See https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration. repartition number partitions used distribute generated table. Use 0 (default) avoid partitioning. memory Boolean; data loaded eagerly memory? (, table cached?) overwrite Boolean; overwrite table given name already exists?","code":""},{"path":"/reference/spark_read_geojson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","text":"tbl","code":""},{"path":[]},{"path":"/reference/spark_read_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a geojson file into a Spark DataFrame.\nRead a geojson file into a Spark DataFrame. — spark_read_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- spark_read_geojson(sc, location = input_location) }"},{"path":"/reference/spark_read_geoparquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","title":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","text":"Read geoparquet file Spark DataFrame. Read geoparquet file Spark DataFrame.","code":""},{"path":"/reference/spark_read_geoparquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","text":"","code":"spark_read_geoparquet(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )"},{"path":"/reference/spark_read_geoparquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","text":"sc spark_connection. name name assign newly generated table. path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. options list strings additional options. See https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration. repartition number partitions used distribute generated table. Use 0 (default) avoid partitioning. memory Boolean; data loaded eagerly memory? (, table cached?) overwrite Boolean; overwrite table given name already exists?","code":""},{"path":"/reference/spark_read_geoparquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","text":"tbl","code":""},{"path":[]},{"path":"/reference/spark_read_geoparquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a geoparquet file into a Spark DataFrame.\nRead a geoparquet file into a Spark DataFrame. — spark_read_geoparquet","text":"","code":"library(sparklyr) #>  #> Attaching package: ‘sparklyr’ #> The following object is masked from ‘package:stats’: #>  #>     filter library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- spark_read_geoparquet(sc, location = input_location) }"},{"path":"/reference/spark_read_geotiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","title":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","text":"Read GeoTiff file Spark DataFrame. Read GeoTiff file Spark DataFrame.","code":""},{"path":"/reference/spark_read_geotiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","text":"","code":"spark_read_geotiff(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )"},{"path":"/reference/spark_read_geotiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","text":"sc spark_connection. name name assign newly generated table. path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. options list strings additional options. See https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration. repartition number partitions used distribute generated table. Use 0 (default) avoid partitioning. memory Boolean; data loaded eagerly memory? (, table cached?) overwrite Boolean; overwrite table given name already exists?","code":""},{"path":"/reference/spark_read_geotiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","text":"tbl","code":""},{"path":[]},{"path":"/reference/spark_read_geotiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a GeoTiff file into a Spark DataFrame.\nRead a GeoTiff file into a Spark DataFrame. — spark_read_geotiff","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- spark_read_geotiff(sc, location = input_location) }"},{"path":"/reference/spark_read_shapefile.html","id":null,"dir":"Reference","previous_headings":"","what":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"Functions read geospatial data variety formats Spark DataFrames. spark_read_shapefile: shapefile spark_read_geojson: geojson file spark_read_geoparquet: geoparquet file spark_read_geotiff: GeoTiff file, folder containing GeoTiff files","code":""},{"path":"/reference/spark_read_shapefile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"","code":"spark_read_shapefile(sc, name = NULL, path = name, options = list(), ...)  spark_read_geojson(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )  spark_read_geoparquet(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )  spark_read_geotiff(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )"},{"path":"/reference/spark_read_shapefile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"sc spark_connection. name name assign newly generated table. path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. options list strings additional options. See https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration. ... Optional arguments; currently unused. repartition number partitions used distribute generated table. Use 0 (default) avoid partitioning. memory Boolean; data loaded eagerly memory? (, table cached?) overwrite Boolean; overwrite table given name already exists?","code":""},{"path":"/reference/spark_read_shapefile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"tbl","code":""},{"path":[]},{"path":"/reference/spark_read_shapefile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- spark_read_shapefile(sc, location = input_location) }"},{"path":"/reference/spark_write_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"Functions write geospatial data variety formats Spark DataFrames. spark_write_geojson: GeoJSON spark_write_geoparquet: GeoParquet spark_write_geotiff: GeoTiff","code":""},{"path":"/reference/spark_write_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"","code":"spark_write_geojson(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )  spark_write_geoparquet(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )  spark_write_geotiff(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )"},{"path":"/reference/spark_write_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"x Spark DataFrame dplyr operation path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. mode character element. Specifies behavior data   table already exists. Supported values include: 'error', 'append', 'overwrite'   ignore. Notice 'overwrite' also change column structure. details see also https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes   version Spark. options list strings additional options. partition_by character vector. Partitions output given columns file system. ... Optional arguments; currently unused.","code":""},{"path":[]},{"path":"/reference/spark_write_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   spark_write_geojson(     tbl %>% dplyr::mutate(id = 1),     output_location = \"/tmp/pts.geojson\"   ) }"},{"path":"/reference/spark_write_geoparquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Spark dataframe into a geoparquet file. — spark_write_geoparquet","title":"Save a Spark dataframe into a geoparquet file. — spark_write_geoparquet","text":"Export spatial Spark dataframe geoparquet file","code":""},{"path":"/reference/spark_write_geoparquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Spark dataframe into a geoparquet file. — spark_write_geoparquet","text":"","code":"spark_write_geoparquet(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )"},{"path":"/reference/spark_write_geoparquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Spark dataframe into a geoparquet file. — spark_write_geoparquet","text":"x Spark DataFrame dplyr operation path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. mode character element. Specifies behavior data   table already exists. Supported values include: 'error', 'append', 'overwrite'   ignore. Notice 'overwrite' also change column structure. details see also https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes   version Spark. options list strings additional options. partition_by character vector. Partitions output given columns file system. ... Optional arguments; currently unused.","code":""},{"path":[]},{"path":"/reference/spark_write_geoparquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a Spark dataframe into a geoparquet file. — spark_write_geoparquet","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   spark_write_geoparquet(     tbl %>% dplyr::mutate(id = 1),     output_location = \"/tmp/pts.geoparquet\"   ) }"},{"path":"/reference/spark_write_geotiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Spark dataframe into a GeoTiff file. — spark_write_geotiff","title":"Save a Spark dataframe into a GeoTiff file. — spark_write_geotiff","text":"Export spatial Spark dataframe GeoTiff file","code":""},{"path":"/reference/spark_write_geotiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Spark dataframe into a GeoTiff file. — spark_write_geotiff","text":"","code":"spark_write_geotiff(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )"},{"path":"/reference/spark_write_geotiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Spark dataframe into a GeoTiff file. — spark_write_geotiff","text":"x Spark DataFrame dplyr operation path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. mode character element. Specifies behavior data   table already exists. Supported values include: 'error', 'append', 'overwrite'   ignore. Notice 'overwrite' also change column structure. details see also https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes   version Spark. options list strings additional options. partition_by character vector. Partitions output given columns file system. ... Optional arguments; currently unused.","code":""},{"path":[]},{"path":"/reference/spark_write_geotiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a Spark dataframe into a GeoTiff file. — spark_write_geotiff","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   spark_write_geotiff(     tbl %>% dplyr::mutate(id = 1),     output_location = \"/tmp/pts.geotiff\"   ) }"},{"path":"/reference/spatial_join_op.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial join operator — spatial_join_op","title":"Spatial join operator — spatial_join_op","text":"R interface Sedona spatial join operator","code":""},{"path":"/reference/spatial_join_op.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial join operator — spatial_join_op","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/spatial_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a spatial query — spatial_query","title":"Execute a spatial query — spatial_query","text":"Given spatial RDD, run spatial query parameterized spatial object x.","code":""},{"path":"/reference/spatial_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a spatial query — spatial_query","text":"rdd Sedona spatial RDD. x query object. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/to_spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"Given Spark dataframe object dplyr expression encapsulating Spark SQL query, build Sedona spatial RDD encapsulate query data source. input contain exactly one spatial column non-spatial columns treated custom user-defined attributes resulting spatial RDD.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"","code":"to_spatial_rdd(x, spatial_col)"},{"path":"/reference/to_spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"x Spark dataframe object sparklyr dplyr expression representing Spark SQL query. spatial_col name spatial column.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"SpatialRDD encapsulating query.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   rdd <- to_spatial_rdd(tbl, \"pt\") }"}]
